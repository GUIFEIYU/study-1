{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aeb5d07c",
   "metadata": {},
   "source": [
    "### python 基础练习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82fbf6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01234\n",
      "01234\n",
      "56789\n",
      "0123456789\n",
      "024\n",
      "012345678\n",
      "9876543210\n",
      "97531\n",
      "01234567890123456789\n",
      "0123456789abc\n"
     ]
    }
   ],
   "source": [
    "str = '0123456789'\n",
    "print(str[0:5])\n",
    "print(str[:5])\n",
    "print(str[5:])\n",
    "print(str[:])\n",
    "# 步长\n",
    "print(str[0:5:2])\n",
    "print(str[:-1])\n",
    "# 倒序\n",
    "print(str[::-1])\n",
    "print(str[::-2])\n",
    "# 重复\n",
    "print(str * 2)\n",
    "# 连接\n",
    "print(str + 'abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d09f665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4]\n",
      "[5, 6, 7, 8, 9, 10]\n",
      "[0, 2, 4, 6, 8]\n",
      "[0, 2, 4, 6, 8, 10]\n",
      "[10, 9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
      "[10, 8, 6, 4, 2, 0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "print(list[0:5])\n",
    "print(list[5:])\n",
    "print(list[0:10:2])\n",
    "print(list[::2])\n",
    "# 倒序输出\n",
    "print(list[::-1])\n",
    "# 倒序输出，每隔两个\n",
    "print(list[::-2])\n",
    "for i in list:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "652d411f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(list), 2):\n",
    "    print(list[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec314ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9, 36, 81]\n",
      "<generator object <genexpr> at 0x0000014EAE9EF2A0>\n",
      "(9, 36, 81)\n",
      "[9, 36, 81]\n"
     ]
    }
   ],
   "source": [
    "# 列表推导式\n",
    "# 列表推导式是一种简洁的方式来创建列表，它可以在一行代码中完成列表的创建和初始化。\n",
    "# 列表推导式的语法如下：\n",
    "# [expression for item in iterable if condition]    # expression 是一个表达式，item 是可迭代对象中的元素，iterable 是可迭代对象，condition 是一个可选的条件表达式。\n",
    "# 列表推导式的执行过程如下：\n",
    "# 1. 遍历可迭代对象中的每个元素。\n",
    "# 2. 对每个元素应用表达式，得到一个新的元素。\n",
    "# 3. 如果条件表达式为真，则将新的元素添加到列表中。\n",
    "# 4. 重复步骤 1-3，直到遍历完可迭代对象中的所有元素。   \n",
    "# 列表推导式的示例：\n",
    "# 创建一个包含 1 到 10 的平方的列表。\n",
    "squares = [x**2 for x in range(1, 11) if x % 3 == 0]\n",
    "print(squares)\n",
    "# 推导元组\n",
    "# 元组推导式是一种简洁的方式来创建元组，它可以在一行代码中  完成元组的创建和初始化。\n",
    "# 元组推导式的语法如下：\n",
    "# (expression for item in iterable if condition)    # expression 是一个表达式，item 是可迭代对象中的元素，iterable 是可迭代对象，condition \n",
    "# 是一个可选的条件表达式。\n",
    "# 元组推导式的执行过程如下：\n",
    "# 1. 遍历可迭代对象中的每个元素。\n",
    "# 2. 对每个元素应用表达式，得到一个新的元素。\n",
    "# 3. 如果条件表达式为真，则\n",
    "# 将新的元素添加到元组中。\n",
    "# 4. 重复步骤 1-3，直到遍历完可迭代对象中的所有元素。\n",
    "# 元组推导式的示例：\n",
    "# 创建一个包含 1 到 10 的平方的元组。\n",
    "squares = (x**2 for x in range(1, 11) if x % 3 == 0)\n",
    "print(squares)\n",
    "print(tuple(squares))\n",
    "# 推导元组变为list\n",
    "# 推导元组变为list的方法有两种：\n",
    "# 1. 使用 list() 函数将元组转换为列表。\n",
    "# 2. 使用方括号 [] 将元组转换为列表。\n",
    "# 推导元组变为list的示例：\n",
    "# 创建一个包含 1 到 10 的平方的元组。\n",
    "squares = (x**2 for x in range(1, 11) if x % 3 == 0)\n",
    "# 使用 list() 函数将元组转换为列表。\n",
    "list1 = list(squares)\n",
    "print(list1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6043fd6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3, 6, 9, 12, 15, 18}\n"
     ]
    }
   ],
   "source": [
    "# 推导集合\n",
    "# 推导集合使用{}\n",
    "# 集合推导式跟列表推导式的使用方法是类似的，只不中括号该改成大括号。\n",
    "# 其操作与列表推导式也是类似的。\n",
    "# 例如：\n",
    "# 我们想生成一个集合，集合元素是能够被3整除的整数\n",
    "s = {x for x in range(1, 20) if x % 3 == 0}\n",
    "print(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aebcd779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Alice': '2341', 'Beth': '9102', 'Cecil': '3258'}\n",
      "{0: ('Alice', '2341'), 1: ('Beth', '9102'), 2: ('Cecil', '3258')}\n"
     ]
    }
   ],
   "source": [
    "# 字典\n",
    "# 字典是一种可变容器模型，可以存储任意类型对象\n",
    "# 字典的每个键值(key=>value)对用冒号(:)分割，每个对之间用逗号(,)分割，整个字典包括在花括号({})中\n",
    "# 键必须是唯一的，但值则不必\n",
    "# 键必须是不可变的，如字符串，数字或元组\n",
    "# 键是唯一的，值可以是任意类型的对象\n",
    "# 字典的创建\n",
    "dict = {'Alice': '2341', 'Beth': '9102', 'Cecil': '3258'}\n",
    "print(dict)\n",
    "\n",
    "# 由列表创建字典，列表中的每个元素都是一个键值对\n",
    "list = [('Alice', '2341'), ('Beth', '9102'), ('Cecil', '3258')]\n",
    "dict2 = {}\n",
    "# 列表的值及其索引作为键值对\n",
    "for key, value in enumerate(list):\n",
    "    dict2[key] = value\n",
    "print(dict2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5b5f0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "help me"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "s = \"help me\"\n",
    "sys.stdout.write(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40c4dd30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'bool'>\n",
      "<class 'bool'>\n"
     ]
    }
   ],
   "source": [
    "# 布尔类型的值和类型\n",
    "a = True\n",
    "b = False\n",
    "print(type(a))  # <class 'bool'>\n",
    "print(type(b))  # <class 'bool'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09557707",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\GUIFEI\\AppData\\Local\\Temp\\ipykernel_2492\\2152914545.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_selected['label'] = df_selected['label'].apply(lambda x: 0 if x < 3 else 1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取xlsx文件\n",
    "df = pd.read_excel('../dataset/jd/jd_comment_data.xlsx')\n",
    "\n",
    "# 提取指定字段（示例字段名为'字段1','字段2','字段3'）\n",
    "selected_columns = ['评价内容(content)', '评分（总分5分）(score)']\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "# 保存为csv文件，重新指定字段的名字 content label（不包含索引）\n",
    "df_selected.columns = ['content', 'label']\n",
    "# 如果label 小于3 则为0， 大于3 则为1\n",
    "df_selected['label'] = df_selected['label'].apply(lambda x: 0 if x < 3 else 1)\n",
    "# 保存为csv文件，重新指定字段的名字 content label（不包含索引）\n",
    "df_selected.to_csv('jd-comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69ddb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, BertForSequenceClassification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"logs\")\n",
    "\n",
    "# 定义数据集类 继承自torch.utils.data.Dataset\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, contents, labels):\n",
    "        self.contents = contents\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        # 返回数据集大小\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # 获取指定索引的文本和标签\n",
    "        content = self.contents[idx]\n",
    "        label = self.labels[idx]\n",
    "        # 返回文本和标签\n",
    "        return content, label\n",
    "\n",
    "def create_dataloader(contents, labels, tokenizer, batch_size=32, shuffle=True):\n",
    "    # 创建数据集\n",
    "    dataset = TextDataset(contents, labels)\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        # 自定义collate函数，用于处理不同长度的文本\n",
    "        contents = [item[0] for item in batch]\n",
    "        labels = [item[1] for item in batch]\n",
    "        # 使用tokenizer处理文本\n",
    "        inputs = tokenizer(\n",
    "            contents, # 文本列表\n",
    "            padding=True, # 填充到最大长度\n",
    "            truncation=True, # 截断到最大长度\n",
    "            max_length=512, # embeding_dim 最大长度\n",
    "            return_tensors=\"pt\" # 返回PyTorch张量\n",
    "        )\n",
    "        return {\n",
    "            'input_ids': inputs['input_ids'],\n",
    "            'attention_mask': inputs['attention_mask'],\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }\n",
    "    # 创建数据加载器\n",
    "    return DataLoader(\n",
    "        dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        collate_fn=collate_fn\n",
    "    )\n",
    "# 加载预训练的BERT模型和分词器\n",
    "model_name = 'bert-base-uncased' # 预训练模型名称\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name) # 加载分词器\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2) # 加载BERT模型，指定标签数量为2（好评和差评）\n",
    "# tensorboard 记录器\n",
    "writer = SummaryWriter()\n",
    "# 检查是否有可用的GPU\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")  # 使用GPU\n",
    "else:\n",
    "    device = torch.device(\"cpu\")  # 使用CPU\n",
    "print(f\"Using device: {device}\")\n",
    "# 读取CSV文件\n",
    "df = pd.read_csv(\"\")\n",
    "# 划分训练集和测试集\n",
    "train_contents, test_contents, train_labels, test_labels = train_test_split(\n",
    "    df['content'], df['label'], test_size=0.2, random_state=42\n",
    ")   \n",
    "# 创建训练集和测试集的数据加载器\n",
    "train_dataloader = create_dataloader(train_contents, train_labels, tokenizer, batch_size=16)\n",
    "test_dataloader = create_dataloader(test_contents, test_labels, tokenizer, batch_size=16)\n",
    "# 定义优化器和损失函数\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5) # 优化器，使用AdamW\n",
    "criterion = torch.nn.CrossEntropyLoss() # 损失函数，使用交叉熵损失  \n",
    "# 训练模型\n",
    "num_epochs = 3 # 训练轮数\n",
    "# 模型加载到GPU\n",
    "model.to(device)\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # 设置模型为训练模式\n",
    "    total_loss = 0 # 初始化总损失\n",
    "    # 训练集数据加载器加载到GPU\n",
    "    train_dataloader = train_dataloader.to(device)\n",
    "    for batch in train_dataloader: # 遍历训练集数据加载器\n",
    "        # 打印数据类型\n",
    "        print(f\"Batch data types: {batch['input_ids'].dtype}, {batch['attention_mask'].dtype}, {batch['labels'].dtype}\")\n",
    "        # 将数据加载到GPU\n",
    "        batch = {k: v for k, v in batch.items()}\n",
    "        # 清零梯度\n",
    "        optimizer.zero_grad()\n",
    "        # 前向传播\n",
    "        outputs = model(**batch) # 调用模型进行前向传播，传入输入数据\n",
    "        # 计算损失\n",
    "        loss = outputs.loss # 从模型输出中获取损失值\n",
    "        # 反向传播\n",
    "        loss.backward() # 反向传播计算梯度\n",
    "        # 更新参数\n",
    "        optimizer.step() # 更新模型参数 \n",
    "        # 打印损失值\n",
    "        print(f\"Batch loss: {loss.item()}\")\n",
    "        # 记录损失值到tensorboard\n",
    "        if writer is not None:\n",
    "            if not torch.isfinite(loss):\n",
    "                print(\"Loss is infinite or NaN, skipping this batch.\")\n",
    "                continue\n",
    "            writer.add_scalar(\"Loss/train\", loss.item(), epoch * len(train_dataloader)) \n",
    "        # 累加损失值\n",
    "        total_loss += loss.item() * batch['input_ids'].size(0) # 累加损失值，乘以批次大小\n",
    "    # 计算平均损失\n",
    "    avg_loss = total_loss / len(train_dataloader.dataset) # 计算平均损失\n",
    "    # 打印结果\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\") # 打印当前轮数和平均损失\n",
    "    # 保存模型\n",
    "    torch.save(model.state_dict(), f\"model_epoch_{epoch+1}.pth\") # 保存模型参数，文件名为\"model_epoch_{epoch+1}.pth\"\n",
    "    print(f\"Model saved as model_epoch_{epoch+1}.pth\") # 打印保存模型的信息\n",
    "\n",
    "    # 验证模型 \n",
    "    model.eval() # 设置模型为评估模式\n",
    "    total_loss = 0 # 初始化总损失\n",
    "    total_correct = 0 # 初始化正确预测数量\n",
    "    total_samples = 0 # 初始化样本数量\n",
    "    with torch.no_grad(): # 禁用梯度计算，减少内存消耗\n",
    "        for batch in test_dataloader: # 遍历测试集数据加载器\n",
    "            # 前向传播  \n",
    "            outputs = model(**batch) # 调用模型进行前向传播，传入输入数据\n",
    "            # 计算损失\n",
    "            loss = outputs.loss # 从模型输出中获取损失值\n",
    "            total_loss += loss.item() * batch['input_ids'].size(0) # 累加损失值，乘以批次大小  \n",
    "            # 计算预测结果\n",
    "            logits = outputs.logits # 从模型输出中获取预测结果\n",
    "            predictions = torch.argmax(logits, dim=-1) # 获取预测结果的类别索引 \n",
    "            # 计算准确率\n",
    "            total_correct += (predictions == batch['labels']).sum().item() # 累加正确预测数量\n",
    "            total_samples += batch['labels'].size(0) # 累加样本数量 \n",
    "    # 计算平均损失和准确率 \n",
    "    avg_loss = total_loss / total_samples # 计算平均损失\n",
    "    accuracy = total_correct / total_samples # 计算准确率\n",
    "    # 打印结果\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Accuracy: {accuracy:.4f}\") # 打印当前轮数、平均损失和准确率\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b491808d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载微调后的模型进行推理\n",
    "model = fasttext.load_model('/kaggle/working/fasttext_model.bin')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "study-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
