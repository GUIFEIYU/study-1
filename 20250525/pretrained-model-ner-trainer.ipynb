{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from transformers import AutoModelForTokenClassification, AutoTokenizer,DataCollatorForTokenClassification\nfrom transformers import TrainingArguments, Trainer\nimport torch\nimport evaluate  # pip install evaluate\nimport seqeval   # pip install seqeval\nfrom datasets import load_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:15:09.077223Z","iopub.execute_input":"2025-05-25T08:15:09.077760Z","iopub.status.idle":"2025-05-25T08:15:09.085407Z","shell.execute_reply.started":"2025-05-25T08:15:09.077732Z","shell.execute_reply":"2025-05-25T08:15:09.084790Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"model = AutoModelForTokenClassification.from_pretrained('google-bert/bert-base-chinese', num_labels=7)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:17.376496Z","iopub.execute_input":"2025-05-25T07:46:17.376952Z","iopub.status.idle":"2025-05-25T07:46:19.805470Z","shell.execute_reply.started":"2025-05-25T07:46:17.376933Z","shell.execute_reply":"2025-05-25T07:46:19.804886Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/624 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35f20845792e4dc5a66dad1d48053ce6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/412M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"573b74f1bf59479e9eca3c6e1b42bf21"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:19.806127Z","iopub.execute_input":"2025-05-25T07:46:19.806441Z","iopub.status.idle":"2025-05-25T07:46:19.811801Z","shell.execute_reply.started":"2025-05-25T07:46:19.806422Z","shell.execute_reply":"2025-05-25T07:46:19.811296Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=7, bias=True)\n)"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained('google-bert/bert-base-chinese')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:19.813071Z","iopub.execute_input":"2025-05-25T07:46:19.813322Z","iopub.status.idle":"2025-05-25T07:46:20.655115Z","shell.execute_reply.started":"2025-05-25T07:46:19.813306Z","shell.execute_reply":"2025-05-25T07:46:20.654409Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db9936bb35ee4b38b09ad0d3b3e27081"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/110k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae2652a5af574d05913c8e8ad74e055d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/269k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"762e38fc87654244856be618e99d21d4"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# 模型测试\nmessage= \"命名实体识别\"\nlabel = torch.tensor([0,1,0,2,5,4])\n\nmodel_input = tokenizer([message], return_tensors='pt')\nresult = model(**model_input)\n\nprint(result.loss)\nprint(result.logits)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:20.655872Z","iopub.execute_input":"2025-05-25T07:46:20.656579Z","iopub.status.idle":"2025-05-25T07:46:20.806211Z","shell.execute_reply.started":"2025-05-25T07:46:20.656559Z","shell.execute_reply":"2025-05-25T07:46:20.805413Z"}},"outputs":[{"name":"stdout","text":"None\ntensor([[[ 0.3466,  0.0680,  0.1839,  0.3548,  0.1633,  0.2896,  0.4516],\n         [ 0.1477, -0.2928,  0.4195, -0.0412, -0.1842,  0.3515,  0.5917],\n         [-0.0289,  0.1072,  0.5445,  0.1000,  0.0958,  0.8696,  0.1344],\n         [-0.1187, -0.1498,  0.2413, -0.3251, -0.0966,  0.6368, -0.3206],\n         [-0.1577, -0.0087,  0.7181, -0.0674,  0.0150,  0.5987, -0.4756],\n         [-0.2419, -0.3130, -0.3713, -0.5937,  0.0140,  0.5136,  0.1689],\n         [-0.0920, -0.1692,  0.4886, -0.0962,  0.2686,  0.3336, -0.0947],\n         [ 0.5450,  0.1952,  0.2713, -0.2293,  0.3201,  0.4604,  0.3622]]],\n       grad_fn=<ViewBackward0>)\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# 加载hf中dataset\nds = load_dataset('nlhappy/CLUE-NER')\nds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:20.807053Z","iopub.execute_input":"2025-05-25T07:46:20.807311Z","iopub.status.idle":"2025-05-25T07:46:22.326490Z","shell.execute_reply.started":"2025-05-25T07:46:20.807293Z","shell.execute_reply":"2025-05-25T07:46:22.325892Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/21.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0990978bdd104d78b0e926977ae5903f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dataset_infos.json:   0%|          | 0.00/970 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3def6a1ccd7b4d8283f3542fa303d956"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-a33d0e4276aef9b4.parquet:   0%|          | 0.00/1.30M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"22b595406b734b698977797f6f48cec0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"(…)-00000-of-00001-07f476b71c5edde6.parquet:   0%|          | 0.00/178k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00db90689565495282231e8420240a18"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/10748 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"286b0fdd3898418e8ac9e80a6637e0cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1343 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a9aca8dd978446f99b029106f64ba58"}},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'ents'],\n        num_rows: 10748\n    })\n    validation: Dataset({\n        features: ['text', 'ents'],\n        num_rows: 1343\n    })\n})"},"metadata":{}}],"execution_count":6},{"cell_type":"markdown","source":"## 实体映射数据集词典准备","metadata":{}},{"cell_type":"code","source":"# entity_index\nentites = ['O'] + list({'movie', 'name', 'game', 'address', 'position', \\\n           'company', 'scene', 'book', 'organization', 'government'})\ntags = ['O']\nfor entity in entites[1:]:\n    tags.append('B-' + entity.upper())\n    tags.append('I-' + entity.upper())\n\nentity_index = {entity:i for i, entity in enumerate(entites)}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:22.327196Z","iopub.execute_input":"2025-05-25T07:46:22.327501Z","iopub.status.idle":"2025-05-25T07:46:22.332054Z","shell.execute_reply.started":"2025-05-25T07:46:22.327483Z","shell.execute_reply":"2025-05-25T07:46:22.331469Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"entity_index","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:22.332733Z","iopub.execute_input":"2025-05-25T07:46:22.333611Z","iopub.status.idle":"2025-05-25T07:46:22.430372Z","shell.execute_reply.started":"2025-05-25T07:46:22.333582Z","shell.execute_reply":"2025-05-25T07:46:22.429703Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"{'O': 0,\n 'government': 1,\n 'position': 2,\n 'company': 3,\n 'movie': 4,\n 'address': 5,\n 'book': 6,\n 'scene': 7,\n 'organization': 8,\n 'game': 9,\n 'name': 10}"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"tags","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:22.431077Z","iopub.execute_input":"2025-05-25T07:46:22.431504Z","iopub.status.idle":"2025-05-25T07:46:22.442581Z","shell.execute_reply.started":"2025-05-25T07:46:22.431481Z","shell.execute_reply":"2025-05-25T07:46:22.442023Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"['O',\n 'B-GOVERNMENT',\n 'I-GOVERNMENT',\n 'B-POSITION',\n 'I-POSITION',\n 'B-COMPANY',\n 'I-COMPANY',\n 'B-MOVIE',\n 'I-MOVIE',\n 'B-ADDRESS',\n 'I-ADDRESS',\n 'B-BOOK',\n 'I-BOOK',\n 'B-SCENE',\n 'I-SCENE',\n 'B-ORGANIZATION',\n 'I-ORGANIZATION',\n 'B-GAME',\n 'I-GAME',\n 'B-NAME',\n 'I-NAME']"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"def entity_tags_proc(item):\n    # item即是dataset中记录\n    text_len = len(item['text'])  # 根据文本长度生成tags列表\n    tags = [0] * text_len    # 初始值为‘O’\n    # 遍历实体列表，所有实体类别标记填入tags\n    entites = item['ents']\n    for ent in entites:\n        indices = ent['indices']  # 实体索引\n        label = ent['label']   # 实体名\n        tags[indices[0]] = entity_index[label] * 2 - 1\n        for idx in indices[1:]:\n            tags[idx] = entity_index[label] * 2\n    return {'ent_tag': tags}\n\n# 使用自定义回调函数处理数据集记录\nds1 = ds.map(entity_tags_proc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:22.444461Z","iopub.execute_input":"2025-05-25T07:46:22.444968Z","iopub.status.idle":"2025-05-25T07:46:23.889323Z","shell.execute_reply.started":"2025-05-25T07:46:22.444952Z","shell.execute_reply":"2025-05-25T07:46:23.888630Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10748 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ebf79e311504f88851b0af8b0934724"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1343 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fac0289c818f4457b72b15f697984330"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# 训练集\nfor row in ds1['train']:\n    print(row['text'])\n    print(row['ent_tag'])\n    \n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:23.890051Z","iopub.execute_input":"2025-05-25T07:46:23.890297Z","iopub.status.idle":"2025-05-25T07:46:23.894974Z","shell.execute_reply.started":"2025-05-25T07:46:23.890270Z","shell.execute_reply":"2025-05-25T07:46:23.894149Z"}},"outputs":[{"name":"stdout","text":"浙商银行企业信贷部叶老桂博士则从另一个角度对五道门槛进行了解读。叶老桂认为，对目前国内商业银行而言，\n[5, 6, 6, 6, 0, 0, 0, 0, 0, 19, 20, 20, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"ds1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:23.895736Z","iopub.execute_input":"2025-05-25T07:46:23.895990Z","iopub.status.idle":"2025-05-25T07:46:23.916991Z","shell.execute_reply.started":"2025-05-25T07:46:23.895968Z","shell.execute_reply":"2025-05-25T07:46:23.916418Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'ents', 'ent_tag'],\n        num_rows: 10748\n    })\n    validation: Dataset({\n        features: ['text', 'ents', 'ent_tag'],\n        num_rows: 1343\n    })\n})"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"中文bert分词在日期时间和英文转换token过程中，出现合并。影响ner标注准确性。","metadata":{}},{"cell_type":"code","source":"token_index = tokenizer.encode('2000年2月add', add_special_tokens=False)\nprint(token_index)\ntokens = tokenizer.decode(token_index)\nprint(tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:23.917739Z","iopub.execute_input":"2025-05-25T07:46:23.918017Z","iopub.status.idle":"2025-05-25T07:46:23.927151Z","shell.execute_reply.started":"2025-05-25T07:46:23.918001Z","shell.execute_reply":"2025-05-25T07:46:23.926488Z"}},"outputs":[{"name":"stdout","text":"[8202, 2399, 123, 3299, 10253]\n2000 年 2 月 add\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"input_data = tokenizer(['2000年2月add'], add_special_tokens=False, truncation=True)\nprint(input_data)\n\ninput_data.word_ids(0) # 返回批次中指定token对应原始文本的索引映射","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:23.927810Z","iopub.execute_input":"2025-05-25T07:46:23.927998Z","iopub.status.idle":"2025-05-25T07:46:23.939401Z","shell.execute_reply.started":"2025-05-25T07:46:23.927984Z","shell.execute_reply":"2025-05-25T07:46:23.938642Z"}},"outputs":[{"name":"stdout","text":"{'input_ids': [[8202, 2399, 123, 3299, 10253]], 'token_type_ids': [[0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1]]}\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"[0, 1, 2, 3, 4]"},"metadata":{}}],"execution_count":14},{"cell_type":"code","source":"# 原始文本转换模型需要token_idx,生成和token_idx对齐label\ndef data_input_proc(item):\n    # 输入文本转换模型输入token索引\n    input_data = tokenizer(item['text'], truncation=True, add_special_tokens=False, max_length=512)\n    adjust_labels = []  # 所有修正后label索引列表\n    # 上一步骤生成ner_tag中索引和token对齐\n    for k in range(len(input_data['input_ids'])):\n        # 每条记录token对应word_ids\n        word_ids = input_data.word_ids(k)\n        # 批次ner_tag长度和token长度对齐\n        tags = item['ent_tag'][k]\n        \n        adjusted_label_ids = []\n        i, prev_wid = -1,-1\n        for wid in word_ids:\n            if (wid != prev_wid):   #  word_ids [1,1,1,2,3,4,5] -> [0,1,2,3,4,5,6]\n                i += 1 # token对应检索位置+1\n                prev_wid = wid\n            adjusted_label_ids.append(tags[i])\n        adjust_labels.append(adjusted_label_ids)                \n    # 修正后label添加到input_data\n    input_data['labels'] = adjust_labels\n    return input_data\n    \n\nds2 = ds1.map(data_input_proc, batched=True)  # batched 每次传入自定义方法样本数量多个","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:23.940347Z","iopub.execute_input":"2025-05-25T07:46:23.940565Z","iopub.status.idle":"2025-05-25T07:46:25.374301Z","shell.execute_reply.started":"2025-05-25T07:46:23.940543Z","shell.execute_reply":"2025-05-25T07:46:25.373604Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/10748 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eab9958349734858959b0e18f313cc67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1343 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"71ab8e36907c4e6d94cb6ea41abb65a6"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# 记录转换为pytorch\nds2.set_format('torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n# ds_new = ds2.with_format('torch', columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:25.375059Z","iopub.execute_input":"2025-05-25T07:46:25.375612Z","iopub.status.idle":"2025-05-25T07:46:25.379571Z","shell.execute_reply.started":"2025-05-25T07:46:25.375585Z","shell.execute_reply":"2025-05-25T07:46:25.378869Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# for item in ds2['train']:\n#     print(item)\n#     break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:25.380235Z","iopub.execute_input":"2025-05-25T07:46:25.380432Z","iopub.status.idle":"2025-05-25T07:46:25.424821Z","shell.execute_reply.started":"2025-05-25T07:46:25.380418Z","shell.execute_reply":"2025-05-25T07:46:25.424082Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"## 模型训练\n### TrainingArguments\n","metadata":{}},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=\"ner_train\",  # 模型训练工作目录（tensorboard，临时模型存盘文件，日志）\n    num_train_epochs = 3,    # 训练 epoch\n    save_safetensors=False,  # 设置False保存文件可以通过torch.load加载\n    per_device_train_batch_size=32,  # 训练批次\n    per_device_eval_batch_size=32,\n    report_to='tensorboard',  # 训练输出记录\n    eval_strategy=\"epoch\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:25.425711Z","iopub.execute_input":"2025-05-25T07:46:25.426007Z","iopub.status.idle":"2025-05-25T07:46:25.464473Z","shell.execute_reply.started":"2025-05-25T07:46:25.425984Z","shell.execute_reply":"2025-05-25T07:46:25.463977Z"}},"outputs":[],"execution_count":18},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"code","source":"id2lbl = {i:tag for i, tag in enumerate(tags)}\nlbl2id = {tag:i for i, tag in enumerate(tags)}\n\nmodel = AutoModelForTokenClassification.from_pretrained('google-bert/bert-base-chinese', \n                                                        num_labels=21,\n                                                        id2label=id2lbl,\n                                                        label2id=lbl2id)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:46:25.465123Z","iopub.execute_input":"2025-05-25T07:46:25.465355Z","iopub.status.idle":"2025-05-25T07:46:25.590947Z","shell.execute_reply.started":"2025-05-25T07:46:25.465330Z","shell.execute_reply":"2025-05-25T07:46:25.590450Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stderr","text":"Some weights of BertForTokenClassification were not initialized from the model checkpoint at google-bert/bert-base-chinese and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"BertForTokenClassification(\n  (bert): BertModel(\n    (embeddings): BertEmbeddings(\n      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): BertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x BertLayer(\n          (attention): BertAttention(\n            (self): BertSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): BertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): BertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): BertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=21, bias=True)\n)"},"metadata":{}}],"execution_count":19},{"cell_type":"markdown","source":"## Trainer","metadata":{}},{"cell_type":"code","source":"# metric 方法\ndef compute_metric(result):\n    # result 是一个tuple (predicts, labels)\n    \n    # 获取评估对象\n    seqeval = evaluate.load('seqeval')\n    predicts,labels = result\n    predicts = np.argmax(prdicts, axis=2)\n    \n    # 准备评估数据\n    predicts = [[tags[p] for p,l in zip(ps,ls) if l != -100]\n                 for ps,ls in zip(predicts,labels)]\n    labels = [[tags[l] for p,l in zip(ps,ls) if l != -100]\n                 for ps,ls in zip(predicts,labels)]\n    results = seqeval.compute(predictions=predicts, references=labels)\n\n    return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:30:01.851176Z","iopub.execute_input":"2025-05-25T08:30:01.851683Z","iopub.status.idle":"2025-05-25T08:30:01.856752Z","shell.execute_reply.started":"2025-05-25T08:30:01.851661Z","shell.execute_reply":"2025-05-25T08:30:01.855998Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer, padding=True)\n\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=ds2['train'],\n    eval_dataset=ds2['validation'],\n    data_collator=data_collator,\n    compute_metrics=compute_metric\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:30:19.058065Z","iopub.execute_input":"2025-05-25T08:30:19.058354Z","iopub.status.idle":"2025-05-25T08:30:19.082537Z","shell.execute_reply.started":"2025-05-25T08:30:19.058336Z","shell.execute_reply":"2025-05-25T08:30:19.081782Z"}},"outputs":[],"execution_count":49},{"cell_type":"markdown","source":"模型训练","metadata":{}},{"cell_type":"code","source":"trainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:30:25.933226Z","iopub.execute_input":"2025-05-25T08:30:25.933488Z","iopub.status.idle":"2025-05-25T08:33:51.068401Z","shell.execute_reply.started":"2025-05-25T08:30:25.933468Z","shell.execute_reply":"2025-05-25T08:33:51.067509Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='504' max='504' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [504/504 03:24, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.175500</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=504, training_loss=0.17525818352661435, metrics={'train_runtime': 204.5277, 'train_samples_per_second': 157.651, 'train_steps_per_second': 2.464, 'total_flos': 820469833815600.0, 'train_loss': 0.17525818352661435, 'epoch': 3.0})"},"metadata":{}}],"execution_count":50},{"cell_type":"markdown","source":"模型推理","metadata":{}},{"cell_type":"code","source":"result = trainer.predict(ds2['validation'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T07:55:07.656319Z","iopub.execute_input":"2025-05-25T07:55:07.657027Z","iopub.status.idle":"2025-05-25T07:55:13.025352Z","shell.execute_reply.started":"2025-05-25T07:55:07.656997Z","shell.execute_reply":"2025-05-25T07:55:13.024775Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"print(ds1['validation'][10]['text'])\nprint(ds2['validation'][10]['labels'])\nprint(result.label_ids[10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:21:27.274620Z","iopub.execute_input":"2025-05-25T08:21:27.274888Z","iopub.status.idle":"2025-05-25T08:21:27.281685Z","shell.execute_reply.started":"2025-05-25T08:21:27.274867Z","shell.execute_reply":"2025-05-25T08:21:27.281116Z"}},"outputs":[{"name":"stdout","text":"根据北京市消防局的说法，此次火灾主要原因是责任单位违规燃放礼花弹，燃放期间民警多次劝阻未果。\ntensor([0, 0, 1, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 0, 0, 0])\n[   0    0    1    2    2    2    2    2    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n    0    0    0    0    0    0    0    0    0    3    4    0    0    0\n    0    0    0    0 -100 -100 -100 -100]\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":" [tags[p] for p,l in zip(result.label_ids[10],ds2['validation'][10]['labels'])]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:24:37.844364Z","iopub.execute_input":"2025-05-25T08:24:37.844890Z","iopub.status.idle":"2025-05-25T08:24:37.851464Z","shell.execute_reply.started":"2025-05-25T08:24:37.844869Z","shell.execute_reply":"2025-05-25T08:24:37.850779Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"['O',\n 'O',\n 'B-GOVERNMENT',\n 'I-GOVERNMENT',\n 'I-GOVERNMENT',\n 'I-GOVERNMENT',\n 'I-GOVERNMENT',\n 'I-GOVERNMENT',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'B-POSITION',\n 'I-POSITION',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O']"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"[tags[l] for p,l in zip(result.label_ids[10],ds2['validation'][10]['labels'])]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-25T08:25:04.723891Z","iopub.execute_input":"2025-05-25T08:25:04.724510Z","iopub.status.idle":"2025-05-25T08:25:04.731215Z","shell.execute_reply.started":"2025-05-25T08:25:04.724487Z","shell.execute_reply":"2025-05-25T08:25:04.730611Z"}},"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"['O',\n 'O',\n 'B-GOVERNMENT',\n 'I-GOVERNMENT',\n 'I-GOVERNMENT',\n 'I-GOVERNMENT',\n 'I-GOVERNMENT',\n 'I-GOVERNMENT',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'B-POSITION',\n 'I-POSITION',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O',\n 'O']"},"metadata":{}}],"execution_count":47}]}